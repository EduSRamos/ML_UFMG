{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as skm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>1.</span> Load Data\n",
    "\n",
    "Fonte: https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame\n",
    "\n",
    "5. Number of Instances: 958 (legal tic-tac-toe endgame boards)\n",
    "\n",
    "6. Number of Attributes: 9, each corresponding to one tic-tac-toe square\n",
    "\n",
    "7. Attribute Information: (`x`=player x has taken, `o`=player o has taken, `b`=blank)\n",
    "\n",
    "    1. top-left-square: {x,o,b}\n",
    "    2. top-middle-square: {x,o,b}\n",
    "    3. top-right-square: {x,o,b}\n",
    "    4. middle-left-square: {x,o,b}\n",
    "    5. middle-middle-square: {x,o,b}\n",
    "    6. middle-right-square: {x,o,b}\n",
    "    7. bottom-left-square: {x,o,b}\n",
    "    8. bottom-middle-square: {x,o,b}\n",
    "    9. bottom-right-square: {x,o,b}\n",
    "    - Class: {`positive`,`negative`}\n",
    "\n",
    "8. Missing Attribute Values: None\n",
    "\n",
    "9. Class Distribution: About 65.3% are positive (i.e., wins for \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tic-tac-toe_data','rb') as f:\n",
    "    raw_data = f.readlines()\n",
    "\n",
    "dataset = np.empty((len(raw_data), 10), dtype=str) # number of samples x (9 positions + result) of type str\n",
    "for i, sample in enumerate(raw_data):\n",
    "    sample = sample.decode('utf-8')                # from bytes to str\n",
    "    dataset[i,:] = sample.strip('\\n').split(',')   # add sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['x', 'x', 'x', ..., 'o', 'o', 'p'],\n",
       "       ['x', 'x', 'x', ..., 'x', 'o', 'p'],\n",
       "       ['x', 'x', 'x', ..., 'o', 'x', 'p'],\n",
       "       ...,\n",
       "       ['o', 'x', 'o', ..., 'o', 'x', 'n'],\n",
       "       ['o', 'x', 'o', ..., 'o', 'x', 'n'],\n",
       "       ['o', 'o', 'x', ..., 'x', 'x', 'n']], dtype='<U1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>1.</span> CART cost function and Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns: CART cost function, predicted class\n",
    "def CART_cost(y, w, idx):\n",
    "    children = (idx,~idx)                    # left and right child in tree\n",
    "    ch_C = []                                # predicted class for each child\n",
    "    ch_P = []                                # probabilities for each child\n",
    "    ch_G = []                                # Gini index for each child\n",
    "    w_sum = np.sum(w)                        # sum of all weights\n",
    "    J = 0                                    # CART cost function\n",
    "    for child in children:\n",
    "        # In case child is empty\n",
    "        if all(child==False):\n",
    "            ch_C.append(None)\n",
    "            ch_G.append(None)\n",
    "            ch_P.append(None)\n",
    "            continue\n",
    "            \n",
    "        w_ch = w[child]                      # weights in node\n",
    "        y_ch = y[child]                      # classes in node\n",
    "        w_sum_ch = np.sum(w_ch)              # sum all weights\n",
    "        G = 1                                # initial Gini index\n",
    "        max_w_sum_ch_cls = 0                 # maximum weight-sum of child's classes\n",
    "        for cls in set(y_ch):\n",
    "            w_sum_ch_cls = np.sum(w_ch[y_ch==cls]) # weight-sum of child's class\n",
    "            G -= (w_sum_ch_cls/w_sum_ch)**2        # squared of weighted-sum for each class\n",
    "            if w_sum_ch_cls > max_w_sum_ch_cls:    # weight-sum of child's class greater than current max\n",
    "                max_w_sum_ch_cls = w_sum_ch_cls\n",
    "                pred_cls = cls\n",
    "                \n",
    "        ch_C.append(pred_cls) # child's predicted class\n",
    "        ch_G.append(G)        # child's Gini index\n",
    "        ch_P.append(max_w_sum_ch_cls/w_sum_ch) # child's probability (predicted-class sum of weights/total)\n",
    "        J += G*w_sum_ch/w_sum # parent node's CART cost\n",
    "        \n",
    "    return J, ch_C, ch_G, ch_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification CART \n",
    "def create_node(X, y, w):\n",
    "    # For each attribute\n",
    "    J_min = np.inf\n",
    "    for att in range(X.shape[-1]):\n",
    "        # For each value of attribute\n",
    "        for val in set(X[:,att]):\n",
    "            # Split dataset\n",
    "            idx = X[:,att]==val # For regression CART, use < instead of ==\n",
    "\n",
    "            # Evaluate (weighted) CART cost function of each child\n",
    "            J, children_Preds, children_Ginis, children_Probs = CART_cost(y, w, idx)\n",
    "            print('X%d == %s Gini=%4.3f'%((att+1), val, J))\n",
    "\n",
    "            # If it is the best GINI so far, replace best node (which is a lambda function)\n",
    "            if J < J_min:\n",
    "                J_min = J\n",
    "                node_att = att\n",
    "                node_val = val\n",
    "                node_ch_Preds = children_Preds\n",
    "                node_ch_Probs = children_Probs\n",
    "                node_ch_Ginis = children_Ginis\n",
    "                node = {'Explanation': 'x[%d] == %s'%(node_att, node_val),\n",
    "                        'Condition': lambda x: x[node_att]==node_val, \n",
    "                        'CART_cost': J_min,\n",
    "                        'Prediction': {True: node_ch_Preds[0], False: node_ch_Preds[1]},\n",
    "                        'Children_Probs': {True: node_ch_Probs[0], False: node_ch_Probs[1]},\n",
    "                        'Children_Ginis': {True: node_ch_Ginis[0], False: node_ch_Ginis[1]}\n",
    "                       }\n",
    "\n",
    "    return node\n",
    "\n",
    "evaluate_node = lambda node,x: node['Prediction'][node['Condition'](x)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# VALIDATION - example in https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "# FIRST must change CART_cost function so that it becomes a regression-type (from '==' to '<')\n",
    "\n",
    "dataset = np.array([[2.771244718,1.784783929,0],\n",
    "[1.728571309,1.169761413,0],\n",
    "[3.678319846,2.81281357,0],\n",
    "[3.961043357,2.61995032,0],\n",
    "[2.999208922,2.209014212,0],\n",
    "[7.497545867,3.162953546,1],\n",
    "[9.00220326,3.339047188,1],\n",
    "[7.444542326,0.476683375,1],\n",
    "[10.12493903,3.234550982,1],\n",
    "[6.642287351,3.319983761,1]])\n",
    "\n",
    "X, y = dataset[:,:-1], dataset[:,-1]\n",
    "w = np.ones(y.shape) # weights\n",
    "node = create_node(X, y, w)\n",
    "\n",
    "# CHECK if X1< 6.642 results in Gini=0\n",
    "\n",
    "# Predictions\n",
    "assert evaluate_node(node,[6.65, 3.33]) == 1\n",
    "\n",
    "assert evaluate_node(node,[6.63, 3.33]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 == x Gini=0.449\n",
      "X1 == o Gini=0.444\n",
      "X1 == b Gini=0.452\n",
      "X2 == x Gini=0.448\n",
      "X2 == o Gini=0.451\n",
      "X2 == b Gini=0.452\n",
      "X3 == x Gini=0.449\n",
      "X3 == o Gini=0.444\n",
      "X3 == b Gini=0.452\n",
      "X4 == x Gini=0.448\n",
      "X4 == o Gini=0.451\n",
      "X4 == b Gini=0.452\n",
      "X5 == b Gini=0.452\n",
      "X5 == o Gini=0.401\n",
      "X5 == x Gini=0.414\n",
      "X6 == b Gini=0.452\n",
      "X6 == o Gini=0.451\n",
      "X6 == x Gini=0.448\n",
      "X7 == x Gini=0.449\n",
      "X7 == o Gini=0.444\n",
      "X7 == b Gini=0.452\n",
      "X8 == x Gini=0.448\n",
      "X8 == o Gini=0.451\n",
      "X8 == b Gini=0.452\n",
      "X9 == x Gini=0.449\n",
      "X9 == o Gini=0.444\n",
      "X9 == b Gini=0.452\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset[:,:-1], dataset[:,-1]\n",
    "w = np.ones(y.shape) # weights\n",
    "node = create_node(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Explanation', 'x[4] == o')\n",
      "('Condition', <function create_node.<locals>.<lambda> at 0x7fe9c3d539d8>)\n",
      "('CART_cost', 0.40054542845980845)\n",
      "('Prediction', {True: 'n', False: 'p'})\n",
      "('Children_Probs', {True: 0.5647058823529412, False: 0.7734627831715211})\n",
      "('Children_Ginis', {True: 0.4916262975778547, False: 0.3504362124401713})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print((key,val)) for key,val in node.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert evaluate_node(node, ['x','x','o','b','o','b','o','x','o']) == 'n' # true negative\n",
    "assert evaluate_node(node, ['x','x','o','b','o','b','o','o','o']) == 'n' # false negative\n",
    "assert evaluate_node(node, ['x','x','o','x','b','b','x','b','o']) == 'p' # false positive\n",
    "assert evaluate_node(node, ['x','x','o','x','x','b','x','o','o']) == 'p' # true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate = lambda y_pred,y_real: float(np.sum(y_pred==y_real)/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>1.</span> Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>2.</span> *AdaBoost*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>3.</span> Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>4.</span> Experimentos\n",
    "\n",
    "- Foram utilizadas funcoes para separar conjuntos de treino/teste e treino/val"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 10 splits de teste\n",
    "test_splits = skm.StratifiedShuffleSplit(n_splits=10, test_size=0.15, random_state=1)\n",
    "\n",
    "test_splits.get_n_splits(X,y)\n",
    "j=0\n",
    "for train_val_idx, test_idx in test_splits.split(X,y):\n",
    "    j+=1\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Validacao: treino-val != teste\n",
    "    assert len(np.intersect1d(train_val_idx, test_idx))==0\n",
    "    \n",
    "    # Imprime\n",
    "    print('Teste #%d' % j)\n",
    "    print('Train_val[\"p\" \"n\"]: [%3d %3d] = %3d'%(sum(y_train_val=='p'),sum(y_train_val=='n'),len(y_train_val)))\n",
    "    print('Test[\"p\" \"n\"]:      [%3d %3d] = %3d'%(sum(y_test=='p'),     sum(y_test=='n'),     len(y_test)))\n",
    "    \n",
    "    # 5-fold CV\n",
    "    val_splits = skm.StratifiedKFold(n_splits=5, random_state=j, shuffle=False)\n",
    "    val_splits.get_n_splits(X_train_val, y_train_val)\n",
    "    \n",
    "    k=0\n",
    "    prev_val_idx=[]\n",
    "    for train_idx, val_idx in val_splits.split(X_train_val, y_train_val):\n",
    "        k+=1\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        # Validacao: treino!=val e conjuntos de validacao sao mutuamente exclusivos\n",
    "        assert len(np.intersect1d(train_idx, val_idx))==0\n",
    "        for pvi in prev_val_idx:\n",
    "            assert len(np.intersect1d(pvi, val_idx))==0\n",
    "        prev_val_idx.append(val_idx)\n",
    "            \n",
    "        # Imprime\n",
    "        print('\\tFold #%d' % k)\n",
    "        print('\\tTrain[\"p\" \"n\"]: [%3d %3d] = %3d' % (sum(y_train=='p'), sum(y_train=='n'), len(y_train)))\n",
    "        print('\\tVal[\"p\" \"n\"]:   [%3d %3d] = %3d' % (sum(y_val=='p'),   sum(y_val=='n'),   len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste #1\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "25 / \n",
      "Teste #2\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "24 / 19 / \n",
      "Teste #3\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "21 / 18 / 20 / \n",
      "Teste #4\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "19 / 22 / 27 / 21 / \n",
      "Teste #5\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "21 / 23 / 26 / 18 / 24 / \n",
      "Teste #6\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "15 / 22 / 24 / 17 / 14 / 17 / \n",
      "Teste #7\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "19 / 26 / 14 / 25 / 24 / 28 / 27 / \n",
      "Teste #8\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "23 / 26 / 26 / 24 / 21 / 21 / 19 / 19 / \n",
      "Teste #9\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "13 / 15 / 17 / 29 / 19 / 23 / 26 / 22 / 19 / \n",
      "Teste #10\n",
      "Train_val[\"p\" \"n\"]: [532 282] = 814\n",
      "Test[\"p\" \"n\"]:      [ 94  50] = 144\n",
      "\tFold #0\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #1\n",
      "\tTrain[\"p\" \"n\"]: [425 225] = 650\n",
      "\tVal[\"p\" \"n\"]:   [107  57] = 164\n",
      "\tFold #2\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #3\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n",
      "\tFold #4\n",
      "\tTrain[\"p\" \"n\"]: [426 226] = 652\n",
      "\tVal[\"p\" \"n\"]:   [106  56] = 162\n"
     ]
    }
   ],
   "source": [
    "n = len(y)                   # numero de amostras\n",
    "p_prop = sum(y=='p') / n     # proporcao de positivos\n",
    "n_prop = sum(y=='n') / n     # proporcao de negativos\n",
    "p_idx = np.where(y=='p')[0]  # indices dos positivos\n",
    "n_idx = np.where(y=='n')[0]  # indices dos negativos\n",
    "\n",
    "# Numero de amostras de cada tipo que devem haver nos te\n",
    "nt = int(round(0.15*n))\n",
    "npt = int(round(nt * p_prop))\n",
    "nnt = nt - npt\n",
    "\n",
    "# 10 testes\n",
    "splits = []\n",
    "prev_test_idx = []\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    p_idx_test = np.random.choice(p_idx, npt, replace=False)\n",
    "    n_idx_test = np.random.choice(n_idx, nnt, replace=False)\n",
    "    p_idx_train_val = np.setdiff1d(p_idx, p_idx_test)\n",
    "    n_idx_train_val = np.setdiff1d(n_idx, n_idx_test)\n",
    "    \n",
    "    test_idx = np.concatenate((p_idx_test, n_idx_test))\n",
    "    train_val_idx = np.setdiff1d(np.arange(n), test_idx)\n",
    "    \n",
    "    # Validacao: treino/val != teste\n",
    "    assert len(np.intersect1d(train_val_idx, test_idx))==0\n",
    "    for pti in prev_test_idx:\n",
    "        print(len(np.intersect1d(pti, test_idx)), end=' / ')\n",
    "    prev_test_idx.append(test_idx)\n",
    "    print()\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Imprime\n",
    "    print('Teste #%d' % (i+1))\n",
    "    print('Train_val[\"p\" \"n\"]: [%3d %3d] = %3d'%(sum(y_train_val=='p'),sum(y_train_val=='n'),len(y_train_val)))\n",
    "    print('Test[\"p\" \"n\"]:      [%3d %3d] = %3d'%(sum(y_test=='p'),     sum(y_test=='n'),     len(y_test)))\n",
    "    \n",
    "    np.random.shuffle(p_idx_train_val)\n",
    "    p_idx_val = np.array_split(p_idx_train_val, 5)\n",
    "    np.random.shuffle(n_idx_train_val)\n",
    "    n_idx_val = np.array_split(n_idx_train_val, 5)\n",
    "    val = [np.concatenate((p_idx_val[k],n_idx_val[k])) for k in range(5)]\n",
    "    train = [np.setdiff1d(train_val_idx, val[k]) for k in range(5)]\n",
    "    \n",
    "    # Salva\n",
    "    splits.append({'test': test_idx, 'val': val, 'train': train})\n",
    "    \n",
    "    prev_val_idx=[]\n",
    "    for k in range(5):\n",
    "        train_idx = train[k]\n",
    "        val_idx = val[k]\n",
    "    \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Validacao: treino!=val e conjuntos de validacao sao mutuamente exclusivos\n",
    "        assert len(np.intersect1d(train_idx, val_idx))==0\n",
    "        assert len(np.intersect1d(train_idx, test_idx))==0\n",
    "        assert len(np.intersect1d(val_idx, test_idx))==0\n",
    "        for pvi in prev_val_idx:\n",
    "            assert len(np.intersect1d(pvi, val_idx))==0\n",
    "        prev_val_idx.append(val_idx)\n",
    "            \n",
    "        # Imprime\n",
    "        print('\\tFold #%d' % k)\n",
    "        print('\\tTrain[\"p\" \"n\"]: [%3d %3d] = %3d' % (sum(y_train=='p'), sum(y_train=='n'), len(y_train)))\n",
    "        print('\\tVal[\"p\" \"n\"]:   [%3d %3d] = %3d' % (sum(y_val=='p'),   sum(y_val=='n'),   len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tests[1]['train'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:orange'>1.1.</span> Design dos experimentos\n",
    "\n",
    "- 10 testes, cada um com um conjunto de teste e uma combinacao de folds \n",
    "    - Utilizar np.random.seed(#) para cada teste\n",
    "    \n",
    "- Testar distribuicao de classes (alternativa: mudar métrica - e.g., AUC)\n",
    "    - Completamente aleatorio\n",
    "    - Stratified shuffle split / stratified k-fold (mantem proporcao de classes)\n",
    "    - Oversampling/undersampling para tratar class imbalance\n",
    "    \n",
    "- Há um máximo de 27 stumps (3 possibilidades para 9 posicoes)\n",
    "    \n",
    "<span style='color:red'>[SO COMENTAR] - Vou utilizar stratified</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:orange'>1.2.</span> Bias-variance tradeoff\n",
    "\n",
    "- Grafico #1: Erro de treino/validacao/teste em funcao do numero de preditores - a cada preditor adicionado faz a avaliaca da validacao cruzada e do teste\n",
    "    - Utiliza 1 (ou uns 3) dos testes (dentre os 10 totais) e salva os erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:orange'>1.3.</span>  Erro vs. Gini vs. Entropia - slide 127\n",
    "\n",
    "- Utiliza todos os testes, com o mesmo critério de CV e tira a média"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:orange'>1.4.</span> Curvas de aprendizado\n",
    "\n",
    "- Pega uns 3 testes, e faz:\n",
    "    - A cada iteracao, acrescenta mais N amostras (manter proporcao aproximada)\n",
    "    - Faz todo o processo, computando o erro de treinamento/validacao/teste, igual em 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>5.</span> Análise de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:crimson'>6.</span> Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:orange'>1.1.</span> Subitem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-env]",
   "language": "python",
   "name": "conda-env-ml-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
